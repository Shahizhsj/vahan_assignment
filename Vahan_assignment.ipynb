{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCEr7bqopW8Q"
      },
      "source": [
        "###This part deals with taking an query in natural language and giving the summary for each paper and producing it in audio format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I5nKBz4Uju4l",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install -q dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QF8PZlQ0h1Qr",
        "outputId": "b395df8f-1472-4b93-cb1c-848203227bbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/413.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q elevenlabs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DFbFO-J9W2Er",
        "outputId": "8aba89af-9bad-4ae0-8f6c-40117bcb5a88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/81.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q arxiv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cjwU56baW4h7"
      },
      "outputs": [],
      "source": [
        "import arxiv\n",
        "client = arxiv.Client()\n",
        "arxiv_search = arxiv.Search(\n",
        "        query=\"AI\",\n",
        "        max_results=2,\n",
        "        sort_by=arxiv.SortCriterion.Relevance\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv6eK6iFXqox",
        "outputId": "8c75f4fb-b066-4aa0-86e3-9048edae986d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Thinking: A framework for rethinking artificial intelligence in practice\n",
            "Intersymbolic AI: Interlinking Symbolic AI and Subsymbolic AI\n"
          ]
        }
      ],
      "source": [
        "results=[]\n",
        "for i in client.results(arxiv_search):\n",
        "  print(i.title)\n",
        "  results.append({\n",
        "      'Author name':i.authors,\n",
        "      'Title':i.title,\n",
        "      'Summary':i.summary,\n",
        "\n",
        "  })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XDW8eQEto1TN",
        "outputId": "3d12e22b-b22a-44bb-ca20-7012f1a3e087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for simpleaudio (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q simpleaudio\n",
        "!pip install -q pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Fywbl1zsiw0K"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import io\n",
        "from pydub import AudioSegment\n",
        "from IPython.display import Audio\n",
        "import simpleaudio as sa\n",
        "\n",
        "def elevenlabs_text_to_speech_and(text):\n",
        "    voice_id = \"EXAVITQu4vr4xnSDxMaL\"\n",
        "    url = f\"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}\"\n",
        "\n",
        "    headers = {\n",
        "        \"xi-api-key\": \"sk_5aab40b4a9867c89c184a141277edf83edc3bbfb82e93d70\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "        \"text\": text,\n",
        "        \"model_id\": \"eleven_flash_v2\",\n",
        "        \"voice_settings\": {\n",
        "            \"stability\": 0.7,\n",
        "            \"similarity_boost\": 0.7\n",
        "        }\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        audio_data = response.content\n",
        "        audio_segment = AudioSegment.from_file(io.BytesIO(audio_data), format=\"mp3\")\n",
        "        wav_data = io.BytesIO()\n",
        "        audio_segment.export(wav_data, format=\"wav\")\n",
        "        display(Audio(wav_data.getvalue(), autoplay=True))  # Plays automatically\n",
        "    else:\n",
        "        print(\"Error:\", response.status_code, response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "g_DToAoQmSni",
        "outputId": "b3eb73c2-f7ca-4822-b2b7-9a31ea544448"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'elevenlabs_text_to_speech_and_play' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-42b27afd2c74>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m    \u001b[0melevenlabs_text_to_speech_and_play\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Summary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m    \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'elevenlabs_text_to_speech_and_play' is not defined"
          ]
        }
      ],
      "source": [
        "for i in results:\n",
        "   elevenlabs_text_to_speech_and_play(i['Summary'])\n",
        "   break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VI7A8terRVm"
      },
      "source": [
        "###Now we will work on documet upload feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_2A8cNoZ1Lx7",
        "outputId": "ce9ba05d-942c-4171-8bfa-345ff186e260"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.6/180.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, pandas\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.4 pandas-2.2.3\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet  langchain-google-genai\n",
        "!pip install -q unstructured\n",
        "%pip install -U -q google-genai\n",
        "!pip install -q faiss-cpu\n",
        "!pip install -q langchain\n",
        "!pip install -q chromadb\n",
        "!pip install -q openai\n",
        "!pip install -q langchain_community\n",
        "!pip install -q langchain_openai\n",
        "!pip install -q langgraph\n",
        "!pip install -q langchain_experimental\n",
        "!pip install -q pypdf\n",
        "%pip install --upgrade --quiet  langchain e2b langchain-community\n",
        "%pip install -q langchain-google-genai\n",
        "!pip install -q e2b\n",
        "!pip install --upgrade numpy pandas\n",
        "!pip install -q gradio\n",
        "!pip install -q \"unstructured[docx]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "vg5aM-Bm3_AW",
        "outputId": "cc65d98a-32d8-4aa2-82ce-2ec17b248699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas\n",
            "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting numpy>=1.23.2 (from pandas)\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pytz, tzdata, six, numpy, python-dateutil, pandas\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.4\n",
            "    Uninstalling numpy-2.2.4:\n",
            "      Successfully uninstalled numpy-2.2.4\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.3\n",
            "    Uninstalling pandas-2.2.3:\n",
            "      Successfully uninstalled pandas-2.2.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.4 pandas-2.2.3 python-dateutil-2.9.0.post0 pytz-2025.2 six-1.17.0 tzdata-2025.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "six"
                ]
              },
              "id": "b6ecdb48af8b4141be6345ed6f84297d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.4\n",
            "    Uninstalling numpy-2.2.4:\n",
            "      Successfully uninstalled numpy-2.2.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.4\n"
          ]
        }
      ],
      "source": [
        "!pip install --force-reinstall pandas\n",
        "!pip install --force-reinstall numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2lT39lfy24mv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.document_loaders import UnstructuredFileLoader, CSVLoader, PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
        "from langchain.agents import Tool\n",
        "from langchain.llms import OpenAI\n",
        "from langchain_community.tools import E2BDataAnalysisTool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.chains import RetrievalQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "T6Qe9R1p26Ve"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"models/gemini-2.0-flash\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    google_api_key=\"AIzaSyC6TmVb5Vk5J0r6z0oCmjvNgzbblDKuf3Y\",\n",
        "    # other params...\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FICp9wB83PPf"
      },
      "outputs": [],
      "source": [
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\",google_api_key=\"AIzaSyC6TmVb5Vk5J0r6z0oCmjvNgzbblDKuf3Y\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def elevenlabs_text_to_speech_and_play(text):\n",
        "    voice_id = \"EXAVITQu4vr4xnSDxMaL\"\n",
        "    url = f\"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}\"\n",
        "\n",
        "    headers = {\n",
        "        \"xi-api-key\": \"sk_5aab40b4a9867c89c184a141277edf83edc3bbfb82e93d70\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "        \"text\": text,\n",
        "        \"model_id\": \"eleven_flash_v2\",\n",
        "        \"voice_settings\": {\n",
        "            \"stability\": 0.7,\n",
        "            \"similarity_boost\": 0.7\n",
        "        }\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        # Return the audio data directly\n",
        "        return response.content\n",
        "    else:\n",
        "        print(\"Error:\", response.status_code, response.text)\n",
        "        return None"
      ],
      "metadata": {
        "id": "nsnygKR_kDqa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8QYfaPcI3U5w"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "template = \"\"\"\n",
        "Use the following context (delimited by <ctx></ctx>) and the chat history (delimited by <hs></hs>) to answer the question:\n",
        "------\n",
        "<ctx>\n",
        "{context}\n",
        "</ctx>\n",
        "------\n",
        "<hs>\n",
        "{history}\n",
        "</hs>\n",
        "------\n",
        "{question}\n",
        "Answer:\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"context\", \"question\"],\n",
        "    template=template,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_systhesis_prompt=\"\"\"you are an expert at anaylizing the research papers.your task is to classify research papers summaries in to one of the user given topic list and after that\n",
        "you need to synthesis the papers in each topic .you should summaries for every topic according to the research papers that you classified in that topic\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "P_bkNmY6Q5pz"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n"
      ],
      "metadata": {
        "id": "0AGjVZkfQkV3"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph"
      ],
      "metadata": {
        "id": "cKWIpPMV-3Fm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "6subRMBX3XOz",
        "outputId": "195706d6-89b9-4381-ec39-ff4892bed4af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://2715a488b08c8c1048.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2715a488b08c8c1048.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Use the following context (delimited by <ctx></ctx>) and the chat history (delimited by <hs></hs>) to answer the question:\n",
            "------\n",
            "<ctx>\n",
            "[22] T. Tieleman and G. Hinton. Divide the gradient by a run-\n",
            "ning average of its recent magnitude. COURSERA: Neural\n",
            "Networks for Machine Learning, 4, 2012. Accessed: 2015-\n",
            "11-05.\n",
            "[23] V . Vanhoucke. Learning visual representations at scale. ICLR,\n",
            "2014.\n",
            "[24] M. Wang, B. Liu, and H. Foroosh. Factorized convolutional\n",
            "neural networks. arXiv preprint arXiv:1608.04337, 2016.\n",
            "[25] M. D. Zeiler and R. Fergus. Visualizing and understanding\n",
            "convolutional networks. In Computer Vision–ECCV 2014,\n",
            "pages 818–833. Springer, 2014.\n",
            "\n",
            "of the non-linearity: for deep feature spaces (e.g. those\n",
            "found in Inception modules) the non-linearity is helpful, but\n",
            "for shallow ones (e.g. the 1-channel deep feature spaces\n",
            "of depthwise separable convolutions) it becomes harmful,\n",
            "possibly due to a loss of information.\n",
            "5. Future directions\n",
            "We noted earlier the existence of a discrete spectrum be-\n",
            "tween regular convolutions and depthwise separable convo-\n",
            "lutions, parametrized by the number of independent channel-\n",
            "space segments used for performing spatial convolutions. In-\n",
            "ception modules are one point on this spectrum. We showed\n",
            "in our empirical evaluation that the extreme formulation of\n",
            "an Inception module, the depthwise separable convolution,\n",
            "may have advantages over regular a regular Inception mod-\n",
            "ule. However, there is no reason to believe that depthwise\n",
            "separable convolutions are optimal. It may be that intermedi-\n",
            "ate points on the spectrum, lying between regular Inception\n",
            "\n",
            "[4] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning\n",
            "for image recognition. arXiv preprint arXiv:1512.03385 ,\n",
            "2015.\n",
            "[5] G. Hinton, O. Vinyals, and J. Dean. Distilling the knowledge\n",
            "in a neural network, 2015.\n",
            "[6] A. Howard. Mobilenets: Efﬁcient convolutional neural net-\n",
            "works for mobile vision applications. Forthcoming.\n",
            "[7] S. Ioffe and C. Szegedy. Batch normalization: Accelerating\n",
            "deep network training by reducing internal covariate shift.\n",
            "In Proceedings of The 32nd International Conference on\n",
            "Machine Learning, pages 448–456, 2015.\n",
            "[8] J. Jin, A. Dundar, and E. Culurciello. Flattened convolutional\n",
            "neural networks for feedforward acceleration. arXiv preprint\n",
            "arXiv:1412.5474, 2014.\n",
            "[9] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet\n",
            "classiﬁcation with deep convolutional neural networks. In\n",
            "Advances in neural information processing systems , pages\n",
            "1097–1105, 2012.\n",
            "[10] Y . LeCun, L. Jackel, L. Bottou, C. Cortes, J. S. Denker,\n",
            "\n",
            "Consider a simpliﬁed version of an Inception module that\n",
            "only uses one size of convolution (e.g. 3x3) and does not\n",
            "include an average pooling tower (ﬁgure 2). This Incep-\n",
            "tion module can be reformulated as a large 1x1 convolution\n",
            "followed by spatial convolutions that would operate on non-\n",
            "overlapping segments of the output channels (ﬁgure 3). This\n",
            "observation naturally raises the question: what is the ef-\n",
            "fect of the number of segments in the partition (and their\n",
            "size)? Would it be reasonable to make a much stronger\n",
            "hypothesis than the Inception hypothesis, and assume that\n",
            "cross-channel correlations and spatial correlations can be\n",
            "mapped completely separately?\n",
            "Figure 1. A canonical Inception module (Inception V3).\n",
            "Figure 2. A simpliﬁed Inception module.\n",
            "1.2. The continuum between convolutions and sep-\n",
            "arable convolutions\n",
            "An “extreme” version of an Inception module, based on\n",
            "this stronger hypothesis, would ﬁrst use a 1x1 convolution to\n",
            "</ctx>\n",
            "------\n",
            "<hs>\n",
            "\n",
            "</hs>\n",
            "------\n",
            "give a title and summarize the doucuemnt in 5 to 6 lines\n",
            "Answer:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Error: 401 {\"detail\":{\"status\":\"quota_exceeded\",\"message\":\"This request exceeds your quota of 10000. You have 49 credits remaining, while 355 credits are required for this request.\"}}\n",
            "Error: 401 {\"detail\":{\"status\":\"quota_exceeded\",\"message\":\"This request exceeds your quota of 10000. You have 49 credits remaining, while 678 credits are required for this request.\"}}\n",
            "Error: 401 {\"detail\":{\"status\":\"quota_exceeded\",\"message\":\"This request exceeds your quota of 10000. You have 49 credits remaining, while 770 credits are required for this request.\"}}\n",
            "Error: 401 {\"detail\":{\"status\":\"quota_exceeded\",\"message\":\"This request exceeds your quota of 10000. You have 49 credits remaining, while 1052 credits are required for this request.\"}}\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://2715a488b08c8c1048.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from langchain.document_loaders import UnstructuredFileLoader, CSVLoader, PyPDFLoader\n",
        "import pandas as pd\n",
        "from langchain.chains import LLMChain\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from langchain.tools import BaseTool\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "import base64\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.vectorstores import FAISS\n",
        "import arxiv\n",
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import List, TypedDict\n",
        "topic=[]\n",
        "qa = None\n",
        "image = None\n",
        "t = 0\n",
        "sumaries=[]\n",
        "\n",
        "def vector(documents):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=\"AIzaSyC6TmVb5Vk5J0r6z0oCmjvNgzbblDKuf3Y\")\n",
        "    db = FAISS.from_documents(texts, embeddings)\n",
        "    retriever = db.as_retriever()\n",
        "    memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True, output_key='answer')\n",
        "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever,chain_type_kwargs={\n",
        "        \"verbose\": True,\n",
        "        \"prompt\": prompt,\n",
        "        \"memory\": ConversationBufferMemory(\n",
        "            memory_key=\"history\",\n",
        "            input_key=\"question\"),\n",
        "    })\n",
        "    return qa\n",
        "\n",
        "def file_upload(file):\n",
        "    global sumaries\n",
        "    global qa  # Indicate that we're modifying the global qa variable\n",
        "    if file.name.endswith('.pdf'):\n",
        "        loader = PyPDFLoader(file.name)\n",
        "        documents = loader.load()\n",
        "        qa = vector(documents)\n",
        "        answer = qa.run({\"query\": 'give a title and summarize the doucuemnt in 5 to 6 lines'})\n",
        "        sumaries.append(answer)\n",
        "        audio = elevenlabs_text_to_speech_and_play(answer)\n",
        "        return answer,audio\n",
        "    elif file.name.endswith('.docx'):\n",
        "        loader = UnstructuredFileLoader(file)\n",
        "        documents = loader.load()\n",
        "        qa = vector(documents)\n",
        "        answer = qa.run({\"query\": 'give a title and summarize the doucuemnt in 5 to 6 lines'})\n",
        "        sumaries.append(answer)\n",
        "        audio = elevenlabs_text_to_speech_and_play(answer)\n",
        "        return answer,audio\n",
        "    elif file.name.endswith('.txt'):\n",
        "        loader = UnstructuredFileLoader(file)\n",
        "        documents = loader.load()\n",
        "        qa = vector(documents)\n",
        "        answer = qa.run({\"query\": 'summarize the doucuemnt in 5 to 6 lines'})\n",
        "        sumaries.append(answer)\n",
        "        elevenlabs_text_to_speech_and_play(answer)\n",
        "        return answer\n",
        "    elif file.name.endswith('.csv'):\n",
        "        df = pd.read_csv(file.name)\n",
        "\n",
        "        qa = create_pandas_dataframe_agent(llm, df, verbose=True, allow_dangerous_code=True)\n",
        "        answer = qa.run({\"query\": 'summarize the doucuemnt in 5 to 6 lines'})\n",
        "        sumaries.append(answer)\n",
        "        elevenlabs_text_to_speech_and_play(answer)\n",
        "        return answer\n",
        "    elif file.name.endswith('.xlsx'):\n",
        "        df = pd.read_excel(file.name)\n",
        "        qa = create_pandas_dataframe_agent(llm, df, verbose=True, allow_dangerous_code=True)\n",
        "        answer = qa.run({\"query\": 'summarize the doucuemnt in 7 to 8 lines'})\n",
        "        sumaries.append(answer)\n",
        "        elevenlabs_text_to_speech_and_play(answer)\n",
        "        return answer\n",
        "    else:\n",
        "      pass\n",
        "def url(link):\n",
        "    try:\n",
        "        loader = WebBaseLoader(link)\n",
        "        docs = loader.load()\n",
        "        if not docs:\n",
        "            return \"Error: No content could be extracted from the URL\"\n",
        "        qa = vector(docs)\n",
        "        answer = qa.run({\"query\": 'summarize the research paper in 7 to 8 lines'})\n",
        "        sumaries.append(answer)\n",
        "        audio = elevenlabs_text_to_speech_and_play(answer)\n",
        "        return answer, audio\n",
        "    except Exception as e:\n",
        "        return f\"Error processing URL: {str(e)}\"\n",
        "def doi(doi_number):\n",
        "  client = arxiv.Client()\n",
        "  arxiv_search = arxiv.Search(id_list=[str(doi_number)])\n",
        "  formatted_result=\"\"\n",
        "  for i, paper in enumerate(client.results(arxiv_search), 1):\n",
        "    formatted_result += f\"\"\"\n",
        "Paper {i}\n",
        "{'='*50}\n",
        "Title: {paper.title}\n",
        "Authors: {format_authors(paper.authors)}\n",
        "\n",
        "Summary:\n",
        "{paper.summary}\n",
        "\n",
        "Link: {paper.entry_id}\n",
        "{'='*50}\n",
        "\n",
        "\"\"\"\n",
        "    if formatted_result:\n",
        "        sumaries.append(formatted_result.strip())\n",
        "        audio = elevenlabs_text_to_speech_and_play(formatted_result.strip())\n",
        "        return formatted_result.strip(),audio\n",
        "    else:\n",
        "        return \"No results found!\"\n",
        "\n",
        "\n",
        "def topic_adder(t):\n",
        "  global topic\n",
        "  topic.append(t)\n",
        "  return topic\n",
        "def format_authors(authors):\n",
        "    if isinstance(authors, list):\n",
        "        return \", \".join([str(author) for author in authors])\n",
        "    return str(authors)\n",
        "def cross_ana():\n",
        "  global topic\n",
        "  global sumaries\n",
        "  new_sum='\\n\\n'.join(sumaries)\n",
        "  template=\"\"\" here are the research paper summaries {} and here is the topic list given my the user {}\"\"\".format(new_sum,' '.join(topic))\n",
        "  client = genai.Client(api_key=\"AIzaSyC6TmVb5Vk5J0r6z0oCmjvNgzbblDKuf3Y\")\n",
        "  response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=cross_systhesis_prompt),\n",
        "    contents=template\n",
        ")\n",
        "  audio = elevenlabs_text_to_speech_and_play(response.text)\n",
        "  return response.text,audio\n",
        "\n",
        "\n",
        "def res(query, sort_option):\n",
        "    global sumaries\n",
        "    try:\n",
        "        client = arxiv.Client()\n",
        "\n",
        "        # Map sort options to arxiv.SortCriterion\n",
        "        sort_criteria = {\n",
        "            \"Relevance\": arxiv.SortCriterion.Relevance,\n",
        "            \"Latest\": arxiv.SortCriterion.SubmittedDate,\n",
        "            \"Updated\": arxiv.SortCriterion.LastUpdatedDate\n",
        "        }\n",
        "\n",
        "        arxiv_search = arxiv.Search(\n",
        "            query=query,\n",
        "            max_results=2,\n",
        "            sort_by=sort_criteria.get(sort_option, arxiv.SortCriterion.Relevance)\n",
        "        )\n",
        "\n",
        "        formatted_result = \"\"\n",
        "        for i, paper in enumerate(client.results(arxiv_search), 1):\n",
        "            sumaries.append(paper.summary)\n",
        "            elevenlabs_text_to_speech_and(paper.summary)\n",
        "            formatted_result += f\"\"\"\n",
        "Paper {i}\n",
        "{'='*50}\n",
        "Title: {paper.title}\n",
        "Authors: {format_authors(paper.authors)}\n",
        "\n",
        "Summary:\n",
        "{paper.summary}\n",
        "\n",
        "Link: {paper.entry_id}\n",
        "{'='*50}\n",
        "\n",
        "\"\"\"\n",
        "        if formatted_result:\n",
        "            return formatted_result.strip()\n",
        "        else:\n",
        "            return \"No results found!\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "# Modified Gradio interface with black text color and improved styling\n",
        "with gr.Blocks(css=\"\"\"\n",
        "    /* Global styles */\n",
        "    * {\n",
        "\n",
        "    }\n",
        "\n",
        "    /* Paper output styling */\n",
        "    .paper-output {\n",
        "        font-family: 'Arial', sans-serif;\n",
        "        line-height: 1.6;\n",
        "        padding: 20px;\n",
        "\n",
        "        border: 1px solid #e0e0e0;\n",
        "        border-radius: 8px;\n",
        "            }\n",
        "\n",
        "    /* Input styling */\n",
        "    .query-input {\n",
        "        margin-bottom: 15px;\n",
        "\n",
        "    }\n",
        "\n",
        "    /* Button styling */\n",
        "    .search-button {\n",
        "\n",
        "        border: 1px solid #d0d0d0;\n",
        "    }\n",
        "\n",
        "    /* Tab styling */\n",
        "    .tab-selected {\n",
        "\n",
        "        border-bottom: 2px solid black;\n",
        "    }\n",
        "\n",
        "    /* Markdown text */\n",
        "    .md-text {\n",
        "\n",
        "    }\n",
        "\"\"\") as demo:\n",
        "    with gr.Tabs() as tabs:\n",
        "        with gr.Tab(\"File summarizer\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                  output=gr.Textbox()\n",
        "                  audio_output = gr.Audio()\n",
        "                with gr.Column():\n",
        "                    file_input = gr.File(\n",
        "                        label=\"Upload a file\",\n",
        "                        elem_classes=[\"black-text\"]\n",
        "                    )\n",
        "                    search_button = gr.Button(\n",
        "                        \"Search\",\n",
        "                        variant=\"primary\",\n",
        "                        elem_classes=[\"search-button\"]\n",
        "                    )\n",
        "                    search_button.click(fn=file_upload, inputs=file_input,outputs=[output, audio_output])\n",
        "\n",
        "\n",
        "        with gr.Tab(\"ArXiv Search\"):\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### ArXiv Paper Search\n",
        "            Enter a search term to find relevant academic papers from ArXiv.\n",
        "            \"\"\", elem_classes=[\"md-text\"])\n",
        "\n",
        "            with gr.Column():\n",
        "                # Search input\n",
        "                text_input = gr.Textbox(\n",
        "                    placeholder='Enter your search query (e.g., \"artificial intelligence\", \"machine learning\")...',\n",
        "                    label=\"Search Query\",\n",
        "                    elem_classes=[\"query-input\", \"black-text\"]\n",
        "                )\n",
        "\n",
        "                # Filter section\n",
        "                with gr.Column(elem_classes=[\"filter-section\"]):\n",
        "                    gr.Markdown(\"### Filters\", elem_classes=[\"md-text\"])\n",
        "                    sort_dropdown = gr.Dropdown(\n",
        "                        choices=[\"Relevance\", \"Latest\", \"Updated\"],\n",
        "                        value=\"Relevance\",\n",
        "                        label=\"Sort By\",\n",
        "                        elem_classes=[\"filter-dropdown\"]\n",
        "                    )\n",
        "\n",
        "                with gr.Row():\n",
        "                    search_button = gr.Button(\n",
        "                        \"Search\",\n",
        "                        variant=\"primary\",\n",
        "                        elem_classes=[\"search-button\"]\n",
        "                    )\n",
        "\n",
        "                text_output = gr.Markdown(\n",
        "                    elem_classes=[\"paper-output\", \"black-text\"],\n",
        "                    label=\"Search Results\"\n",
        "                )\n",
        "\n",
        "            search_button.click(\n",
        "                fn=res,\n",
        "                inputs=[text_input, sort_dropdown],\n",
        "                outputs=text_output,\n",
        "                api_name=\"arxiv_search\"\n",
        "            )\n",
        "            text_input.submit(\n",
        "                fn=res,\n",
        "                inputs=[text_input, sort_dropdown],\n",
        "                outputs=text_output\n",
        "            )\n",
        "\n",
        "\n",
        "            gr.Markdown(\"\"\"\n",
        "            #### Search Tips:\n",
        "            - Use specific keywords for better results\n",
        "            - Enclose exact phrases in quotes\n",
        "            - Try different combinations of keywords\n",
        "            - Use filters to sort results by relevance or date\n",
        "            \"\"\", elem_classes=[\"md-text\"])\n",
        "        with gr.Tab('URL Summarizer'):\n",
        "          input=gr.Textbox()\n",
        "          output=gr.Textbox()\n",
        "          audio_output=gr.Audio()\n",
        "          search_button = gr.Button(\n",
        "                        \"Summarize\",\n",
        "                        variant=\"primary\",\n",
        "                        elem_classes=[\"search-button\"]\n",
        "                    )\n",
        "          search_button.click(fn=url, inputs=input,outputs=[output,audio_output])\n",
        "        with gr.Tab('DOI Reference'):\n",
        "          input=gr.Textbox()\n",
        "          output=gr.Textbox()\n",
        "          audio_output=gr.Audio()\n",
        "          search_button = gr.Button(\n",
        "                        \"Summarize\",\n",
        "                        variant=\"primary\",\n",
        "                        elem_classes=[\"search-button\"]\n",
        "                    )\n",
        "          search_button.click(fn=doi, inputs=input,outputs=[output,audio_output])\n",
        "        with gr.Tab(\"Cross-paper synthesis\"):\n",
        "          input=gr.Textbox()\n",
        "          output=gr.Textbox()\n",
        "          audio=gr.Audio()\n",
        "          sumary=gr.Button(\"Summarize\",variant=\"primary\")\n",
        "          input.submit(fn=topic_adder,inputs=input,outputs=output)\n",
        "          sumary.click(fn=cross_ana,inputs=None,outputs=[output,audio])\n",
        "\n",
        "\n",
        "\n",
        "# Launch the demo\n",
        "demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tommarow\n",
        "1)add the url extraction of papers\n",
        "2)add podcast button and add classifications also"
      ],
      "metadata": {
        "id": "SWxr1_tTR_SJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "1NKdkM4B3Yvm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f8ea98e0-cbdb-41e8-aeac-578389363ced"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "sumaries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=['this sis','b']\n",
        "print('\\n'.join(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDVZfeDzMpba",
        "outputId": "17fb1e8c-393e-4634-be48-b31e0ed40691"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this sis\n",
            "b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z9KnY91fO1gx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}